{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/091_dlops_deployment/091_dlops_deployment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLOps - Despliegue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post vamos a aprender como desplegar nuestros modelos en producción. Para ello usaremos [FastAPI](https://fastapi.tiangolo.com/), un *framework* de Python para el desarrollo de APIs, [Docker](https://www.docker.com/) para paquetizar la API y [Heroku](https://www.heroku.com/) para desplegar la API en producción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien existen diferente frameworks para crear APIs en Python, como Flask por ejemplo, aquí vamos a usar `FastAPI` ya que nos ofrece un montón de funcionalidad que usaremos a lo largo de esta serie de posts. Si no conoces este proyecto, te recomiendo que navegues por su [documentación](https://fastapi.tiangolo.com/tutorial/).\n",
    "\n",
    "> Pudes instalar FastAPI con el comando `pip install fastapi[all]`.\n",
    "\n",
    "Una vez instalado, crea un script llamado `app.py` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "```\n",
    "\n",
    "Ahora, puedes arrancar tu API en local con el comando `uvicorn app:app --reload`. Si todo va bien, deberías ver un mensaje similar a\n",
    "\n",
    "![](./pics/flask1.png)\n",
    "\n",
    "Si ahora abres tu navegador y escribes `http://localhost:8000/`, deberás ver el mensaje devuelto por la API.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"message\": \"Hello World\"\n",
    "}\n",
    "```\n",
    "\n",
    "Sencillo, ¿verdad? Ahora simplemente tenemos que hacer que esta API (que como puedes ver no es más que un script de Python) carge nuestro modelo, reciba entradas (en nuestro caso imágenes) y devuelva las predicciones. Esto lo conseguiremos con el siguiente código:\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from PIL import Image\n",
    "import onnxruntime as ort \n",
    "import numpy as np\n",
    "import io\n",
    "import math\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "ort_session = ort.InferenceSession('models/binary_classifier_3.onnx')\n",
    "TRHESHOLD = 0.5\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    request_object_content = await file.read()\n",
    "    img = Image.open(io.BytesIO(request_object_content))\n",
    "    input = np.expand_dims(np.array(img, dtype=np.uint8), axis=0)\n",
    "    ort_inputs = {\n",
    "        \"input\": input\n",
    "    }\n",
    "    ort_output = ort_session.run(['output'], ort_inputs)[0]\n",
    "    output = sigmoid(ort_output)\n",
    "    return {\n",
    "        \"proba\": output,\n",
    "        \"label\": \"3\" if output > TRHESHOLD else \"no 3\"\n",
    "    }\n",
    "```\n",
    "\n",
    "Una de las ventajas que FastAPI ofrece es la de generación automática de documentación interactiva. Si visitas `http://localhost:8000/docs`, podrás probar tu nuevo *endpoint* al cual enviarle imágenes y recibir las predicciones del modelo. Siéntete libre de personalizar tu API a tu gusto 😁."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez implementada la lógica de nuestra API es momento de desplegarla en la nube para que todo el mundo tenga acceso. Sin embargo, para facilitar este proceso, primero crearemos una imágen de `Docker` que contendrá el código de nuestra `API` y todas sus dependencias. Esto nos evitará dolores de cabeza a la hora de crear el entorno de producción adecuado (versión de sistema operativo, versión de dependencias, ...). Simplemente, si nuestro servidor tiene `Docker` instalado, será capaz de ejecutar nuestra `API`. \n",
    "\n",
    "> Puedes instalar `Docker` siguiendo las [instrucciones](https://docs.docker.com/engine/install/).\n",
    "\n",
    "Crea un archivo llamado `Dockerfile` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN conda install -y -c conda-forge \\ \n",
    "    pillow \\\n",
    "    onnxruntime \\\n",
    "    fastapi \\ \n",
    "    uvicorn \\\n",
    "    python-multipart \n",
    "\n",
    "COPY ./models /models\n",
    "COPY ./app.py /app.py\n",
    "\n",
    "CMD uvicorn app:app --host=0.0.0.0\n",
    "```\n",
    "\n",
    "Y, para crear la imagen de `Docker`, ejecuta el comando `docker build -t dlops .`, donde `dlops` es el nombre que le quieras dar a tu imagen. Ahora podrás ejectuar la imágen de `Docker` con el comando `docker run -p 8000:8000 dlops` para arrancar la API.\n",
    "\n",
    "> Durante el desarrollo con `Docker` no es recomendable copiar directamente tu código fuente en el paso de `build`, ya que si haces cambios estos no se reflejarán hasta que hagas un nuevo `build`. Para ello te dejo como ejemplo el archivo `Dockerfile.dev` y `docker-compose-yml`, que \"montan\" el código como un volumen dentro de la imagen `Docker` y por lo tanto estos cambios si se verán reflejados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último paso es el de subir nuestra imagen de `Docker` a `Heroku` y ejectuarla para obtener ana `url` pública con la que tener acceso a nuestra `API`. \n",
    "\n",
    "> Puedes instalar la `CLI` de Horeku siguiendo las [instrucciones](https://devcenter.heroku.com/articles/heroku-cli#install-the-heroku-cli).\n",
    "\n",
    "Lo primero que necesitaremos será logearnos en Heroku usando la CLI.\n",
    "\n",
    "```\n",
    "heroku login\n",
    "```\n",
    "\n",
    "Una vez logeados deberemos generar las credenciales necesarias para guardar nuestra imagen de `Docker` en el registro de `Heroku`\n",
    "\n",
    "```\n",
    "heroku container:login\n",
    "```\n",
    "\n",
    "Con el comando `hrekou create` podemos crear una nueva aplicación, de la cual obtendremos una `url` pública. Para desplegar nuestra apliación deberemos ejecutar el siguiente comando:\n",
    "\n",
    "```\n",
    "heroku container:push web -a <nombre>\n",
    "```\n",
    "\n",
    "donde `<nombre>` es el subdominio de la `url` generada en el paso anterior. La imagen de `Docker` se subirá al registro y ya podemos desplegarla con el comando\n",
    "\n",
    "```\n",
    "heroku container:release web -a <nombre>\n",
    "```\n",
    "\n",
    "¡Voilà! Nuestra API está desplegada y tenemos acceso a través de la `url` generada. Puedes probar a navegar a la documentación (recuerda el endpoint `/docs` que hemos visto antes) y probar tu modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
